{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPt7NoMYTBLRHMACsOHsKqp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVf_5bgXy39b","executionInfo":{"status":"ok","timestamp":1668608207028,"user_tz":-540,"elapsed":1849,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"0410d84c-b901-4abd-db0f-1f25424351e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'KoGPT2-chatbot'...\n","remote: Enumerating objects: 100, done.\u001b[K\n","remote: Counting objects: 100% (22/22), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 100 (delta 16), reused 15 (delta 15), pack-reused 78\u001b[K\n","Receiving objects: 100% (100/100), 113.50 KiB | 4.20 MiB/s, done.\n","Resolving deltas: 100% (53/53), done.\n","Submodule 'Chatbot_data' (https://github.com/haven-jeon/Chatbot_data.git) registered for path 'Chatbot_data'\n","Cloning into '/content/KoGPT2-chatbot/Chatbot_data'...\n","remote: Enumerating objects: 24, done.        \n","remote: Counting objects: 100% (4/4), done.        \n","remote: Compressing objects: 100% (4/4), done.        \n","remote: Total 24 (delta 0), reused 3 (delta 0), pack-reused 20        \n","Submodule path 'Chatbot_data': checked out '235fac5aea3badab22743f7048afe936cf72f822'\n"]}],"source":["!git clone --recurse-submodules https://github.com/haven-jeon/KoGPT2-chatbot.git"]},{"cell_type":"code","source":["cd KoGPT2-chatbot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WGX8tVRzJov","executionInfo":{"status":"ok","timestamp":1668608219111,"user_tz":-540,"elapsed":5,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"73337bc6-cbb6-478d-d19b-446866127d9e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/KoGPT2-chatbot\n"]}]},{"cell_type":"code","source":["!pip3 install -r requirements.txt "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DufGXvr8zNPA","executionInfo":{"status":"ok","timestamp":1668608239504,"user_tz":-540,"elapsed":10758,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"fbd8583f-275a-49a0-f8b0-c1fb92daa94c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Collecting pytorch_lightning==1.2.10\n","  Downloading pytorch_lightning-1.2.10-py3-none-any.whl (841 kB)\n","\u001b[K     |████████████████████████████████| 841 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.12.1+cu113)\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (6.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (4.64.1)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2.9.1)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.21.6)\n","Collecting torchmetrics==0.2.0\n","  Downloading torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n","\u001b[K     |████████████████████████████████| 176 kB 88.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (21.3)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 63.8 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2022.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (3.8.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 81.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 3)) (4.1.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.8.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (22.1.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2.14.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.50.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.38.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.4.6)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.19.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1->-r requirements.txt (line 4)) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.2.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.0.9)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1->-r requirements.txt (line 4)) (1.2.0)\n","Building wheels for collected packages: future, sacremoses\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=864cff39a8f0c329a779494f741f8d56acf94c7dbba62ed38fd4d12598c30a8f\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=4aa4734334d956b9cb2860ea974b95b9a51cb202ef6b0ec58abee39aee897160\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built future sacremoses\n","Installing collected packages: torchmetrics, tokenizers, sacremoses, future, transformers, pytorch-lightning\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed future-0.18.2 pytorch-lightning-1.2.10 sacremoses-0.0.53 tokenizers-0.10.3 torchmetrics-0.2.0 transformers-4.5.1\n"]}]},{"cell_type":"code","source":["!pip install torchtext==0.10.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6GlJOmJzYAD","executionInfo":{"status":"ok","timestamp":1668608397389,"user_tz":-540,"elapsed":86034,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"f67ecd51-94d7-4d69-84b5-a510f171af39"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.9 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 python train_torch.py --gpus 1 --train --max_epochs 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nApiLfx7zjvr","executionInfo":{"status":"ok","timestamp":1668608422114,"user_tz":-540,"elapsed":18166,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"46d53af2-3d44-4e5d-871a-4b64bde168f6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-16 14:20:04.543165: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Downloading: 100% 2.83M/2.83M [00:00<00:00, 17.3MB/s]\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=96, benchmark=False, chat=False, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, enable_pl_optimizer=None, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_val=0, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=5e-05, max_epochs=2, max_len=32, max_steps=None, min_epochs=None, min_steps=None, model_params='model_chp/model_-last.ckpt', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, sentiment='0', stochastic_weight_avg=False, sync_batchnorm=False, terminate_on_nan=False, tpu_cores=None, track_grad_norm=-1, train=True, truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n","Downloading: 100% 1.00k/1.00k [00:00<00:00, 972kB/s]\n","Downloading: 100% 513M/513M [00:06<00:00, 74.2MB/s]\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py:106: UserWarning: \n","A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the A100-SXM4-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","\n","  | Name          | Type             | Params\n","---------------------------------------------------\n","0 | kogpt2        | GPT2LMHeadModel  | 125 M \n","1 | loss_function | CrossEntropyLoss | 0     \n","---------------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n","Epoch 0:   0% 0/124 [00:00<?, ?it/s] INFO:root:contexts : 공허하네\n","INFO:root:contexts : 나한테 마음 떠난 사람이랑 계속 사귀기?\n","INFO:root:toked ctx: ['<usr>', '▁공', '허', '하', '네', '<unused1>', '▁1']\n","INFO:root:response : 제가 채워줄게요.\n","INFO:root:toked ctx: ['<usr>', '▁나한', '테', '▁마음', '▁떠난', '▁사람이', '랑', '▁계속', '▁사귀', '기', '?', '<unused1>', '▁2']\n","INFO:root:toked response : ['<sys>', '▁제가', '▁채워', '줄', '게', '요.', '</s>']\n","INFO:root:response : 사랑 받으면서 사세요.\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁제가', '▁채워', '줄', '게', '요.', '</s>']\n","INFO:root:toked response : ['<sys>', '▁사랑', '▁받으면서', '▁사', '세', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁사랑', '▁받으면서', '▁사', '세', '요.', '</s>']\n","Epoch 0:   0% 0/124 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"train_torch.py\", line 238, in <module>\n","    trainer.fit(model)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 499, in fit\n","    self.dispatch()\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 546, in dispatch\n","    self.accelerator.start_training(self)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 73, in start_training\n","    self.training_type_plugin.start_training(trainer)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 114, in start_training\n","    self._results = trainer.run_train()\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 637, in run_train\n","    self.train_loop.run_training_epoch()\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 492, in run_training_epoch\n","    batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 654, in run_training_batch\n","    self.optimizer_step(optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 433, in optimizer_step\n","    using_lbfgs=is_lbfgs,\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1390, in optimizer_step\n","    optimizer.step(closure=optimizer_closure)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 214, in step\n","    self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 134, in __optimizer_step\n","    trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 277, in optimizer_step\n","    self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 282, in run_optimizer_step\n","    self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 163, in optimizer_step\n","    optimizer.step(closure=lambda_closure, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n","    return wrapped(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\", line 318, in step\n","    loss = closure()\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 649, in train_step_and_backward_closure\n","    split_batch, batch_idx, opt_idx, optimizer, self.trainer.hiddens\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 742, in training_step_and_backward\n","    result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 293, in training_step\n","    training_step_output = self.trainer.accelerator.training_step(args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 156, in training_step\n","    return self.training_type_plugin.training_step(*args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 125, in training_step\n","    return self.lightning_module.training_step(*args, **kwargs)\n","  File \"train_torch.py\", line 151, in training_step\n","    out = self(token_ids)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"train_torch.py\", line 146, in forward\n","    output = self.kogpt2(inputs, return_dict=True)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 917, in forward\n","    return_dict=return_dict,\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 654, in forward\n","    position_ids = torch.arange(past_length, input_shape[-1] + past_length, dtype=torch.long, device=device)\n","RuntimeError: CUDA error: no kernel image is available for execution on the device\n","CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n","For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"]}]},{"cell_type":"code","source":["!export TORCH_CUDA_ARCH_LIST=<compute capability>"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QflqC3GUz6SC","executionInfo":{"status":"ok","timestamp":1668608497870,"user_tz":-540,"elapsed":7,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"f86223dd-f967-4b78-d9f1-dda70eacc137"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n","/bin/bash: -c: line 0: `export TORCH_CUDA_ARCH_LIST=<compute capability>'\n"]}]},{"cell_type":"code","source":["!export TORCH_CUDA_ARCH_LIST=8.0"],"metadata":{"id":"Xe9Ea1Ms0QWc","executionInfo":{"status":"ok","timestamp":1668608520756,"user_tz":-540,"elapsed":474,"user":{"displayName":"구달","userId":"13265385226373116446"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4byRIcTi0W3n","executionInfo":{"status":"ok","timestamp":1668608777087,"user_tz":-540,"elapsed":104552,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"4a1bd477-80ab-45da-a0cb-63a00b46b881"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.6 MB/s eta 0:12:30tcmalloc: large alloc 1147494400 bytes == 0x39cf4000 @  0x7f5b0d89a615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:58tcmalloc: large alloc 1434370048 bytes == 0x7e34a000 @  0x7f5b0d89a615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |█████████████████████           | 1336.2 MB 78.7 MB/s eta 0:00:09tcmalloc: large alloc 1792966656 bytes == 0x317c000 @  0x7f5b0d89a615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 117.7 MB/s eta 0:00:03tcmalloc: large alloc 2241208320 bytes == 0x6df64000 @  0x7f5b0d89a615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf38c6000 @  0x7f5b0d8991e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n","tcmalloc: large alloc 2551685120 bytes == 0x1e1844000 @  0x7f5b0d89a615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n","\u001b[K     |████████████████████████████████| 2041.3 MB 8.1 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.2 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0\n","    Uninstalling torch-1.9.0:\n","      Successfully uninstalled torch-1.9.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 python train_torch.py --gpus 1 --train --max_epochs 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d3y6FEi07tr","executionInfo":{"status":"ok","timestamp":1668608857464,"user_tz":-540,"elapsed":66866,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"96e1e8ea-ac40-422b-e641-be8e3faef651"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-16 14:26:32.095005: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=96, benchmark=False, chat=False, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, enable_pl_optimizer=None, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_val=0, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=5e-05, max_epochs=2, max_len=32, max_steps=None, min_epochs=None, min_steps=None, model_params='model_chp/model_-last.ckpt', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, sentiment='0', stochastic_weight_avg=False, sync_batchnorm=False, terminate_on_nan=False, tpu_cores=None, track_grad_norm=-1, train=True, truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name          | Type             | Params\n","---------------------------------------------------\n","0 | kogpt2        | GPT2LMHeadModel  | 125 M \n","1 | loss_function | CrossEntropyLoss | 0     \n","---------------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n","Epoch 0:   0% 0/124 [00:00<?, ?it/s] INFO:root:contexts : 아직도 헷갈리네\n","INFO:root:toked ctx: ['<usr>', '▁아직도', '▁', '헷', '갈', '리', '네', '<unused1>', '▁1']\n","INFO:root:response : 직감을 믿으세요.\n","INFO:root:toked response : ['<sys>', '▁직', '감을', '▁믿', '으', '세', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁직', '감을', '▁믿', '으', '세', '요.', '</s>']\n","INFO:root:contexts : 계속 맴돈다.\n","INFO:root:toked ctx: ['<usr>', '▁계속', '▁', '맴', '돈', '다.', '<unused1>', '▁1']\n","INFO:root:response : 한동안은 그럴거예요.\n","INFO:root:toked response : ['<sys>', '▁한동안', '은', '▁그럴', '거', '예', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁한동안', '은', '▁그럴', '거', '예', '요.', '</s>']\n","Epoch 0: 100% 124/124 [00:13<00:00,  9.45it/s, loss=28.4, v_num=1]Epoch 0, global step 123: train_loss reached 30.37107 (best 30.37107), saving model to \"/content/KoGPT2-chatbot/model_chp/model_-epoch=00-train_loss=30.37.ckpt\" as top 1\n","tcmalloc: large alloc 1180934144 bytes == 0x12d0e6000 @  0x7f3f72c6d615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f3f48f569e4 0x7f3f48f5f0e4 0x7f3f48f33bf0 0x7f3ea6a59935 0x7f3ea6a5526e 0x7f3ea6a5a40a 0x7f3f48f3413e 0x7f3f489c9f98 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50c4fc 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37\n","tcmalloc: large alloc 1476173824 bytes == 0x174022000 @  0x7f3f72c6d615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f3f48f569e4 0x7f3f48f5f0e4 0x7f3f48f33bf0 0x7f3ea6a59935 0x7f3ea6a5526e 0x7f3ea6a5a40a 0x7f3f48f3413e 0x7f3f489c9f98 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50c4fc 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37\n","tcmalloc: large alloc 1845223424 bytes == 0x7f3a3c042000 @  0x7f3f72c6d615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f3f48f569e4 0x7f3f48f5f0e4 0x7f3f48f33bf0 0x7f3ea6a59935 0x7f3ea6a5526e 0x7f3ea6a5a40a 0x7f3f48f3413e 0x7f3f489c9f98 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50c4fc 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37\n","tcmalloc: large alloc 1845223424 bytes == 0x7f3a3c042000 @  0x7f3f72c6d615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f3f48f569e4 0x7f3f48f5f0e4 0x7f3f48f33bf0 0x7f3ea6a59935 0x7f3ea6a5526e 0x7f3ea6a5a40a 0x7f3f48f3413e 0x7f3f489c9f98 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50c4fc 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37\n","Epoch 1:   0% 0/124 [00:00<?, ?it/s, loss=28.4, v_num=1]INFO:root:contexts : 목욕탕 가야지\n","INFO:root:toked ctx: ['<usr>', '▁목욕', '탕', '▁가야', '지', '<unused1>', '▁0']\n","INFO:root:response : 시원하게 씻고 오세요.\n","INFO:root:toked response : ['<sys>', '▁시원', '하게', '▁씻', '고', '▁오세', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁시원', '하게', '▁씻', '고', '▁오세', '요.', '</s>']\n","INFO:root:contexts : 제가 먼저 파혼 하자고 매달리고 있습니다\n","INFO:root:toked ctx: ['<usr>', '▁제가', '▁먼저', '▁파', '혼', '▁하자', '고', '▁매달', '리고', '▁있', '습니', '다', '<unused1>', '▁1']\n","INFO:root:response : 본인의 선택이라면 존중합니다.\n","INFO:root:toked response : ['<sys>', '▁본인의', '▁선택', '이라면', '▁존중', '합니다.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁본인의', '▁선택', '이라면', '▁존중', '합니다.', '</s>']\n","Epoch 1: 100% 124/124 [00:13<00:00,  9.42it/s, loss=27, v_num=1]Epoch 1, global step 247: train_loss reached 29.25697 (best 29.25697), saving model to \"/content/KoGPT2-chatbot/model_chp/model_-epoch=01-train_loss=29.26.ckpt\" as top 1\n","tcmalloc: large alloc 1845223424 bytes == 0x7f3a3c042000 @  0x7f3f72c6d615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f3f48f569e4 0x7f3f48f5f0e4 0x7f3f48f33bf0 0x7f3ea6a59935 0x7f3ea6a5526e 0x7f3ea6a5a40a 0x7f3f48f3413e 0x7f3f489c9f98 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50c4fc 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37\n","Saving latest checkpoint...\n","Epoch 1: 100% 124/124 [00:25<00:00,  4.93it/s, loss=27, v_num=1]\n","INFO:root:best model path /content/KoGPT2-chatbot/model_chp/model_-epoch=01-train_loss=29.26.ckpt\n"]}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 python train_torch.py --gpus 1 --chat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtxzyXKC1Yl6","executionInfo":{"status":"ok","timestamp":1668609374247,"user_tz":-540,"elapsed":439260,"user":{"displayName":"구달","userId":"13265385226373116446"}},"outputId":"d8e17c16-87ac-49c1-a3f8-572f92fe05b8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-16 14:28:55.482771: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=96, benchmark=False, chat=True, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, enable_pl_optimizer=None, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_val=0, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=5e-05, max_epochs=None, max_len=32, max_steps=None, min_epochs=None, min_steps=None, model_params='model_chp/model_-last.ckpt', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, sentiment='0', stochastic_weight_avg=False, sync_batchnorm=False, terminate_on_nan=False, tpu_cores=None, track_grad_norm=-1, train=False, truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n","user > 안녕\n","Simsimi > 안녕히 주무세요.\n","user > 녕\n","Simsimi > 안녕하세요.\n","user > 날씨가 춥다\n","Simsimi > 감기 조심하세요.\n","user > 다\n","Simsimi > 다 잘 될 거예요.\n","user > 날씨도 좋은데 산책가자\n","Simsimi > 산책도 좋죠.\n","user > 자\n","Simsimi > 좋은 생각이에요.\n","user > 살 빼고 싶은데 어떻게 해야 하지?\n","Simsimi > 저는 살 빼고 싶어요.\n","user > 내일 출근해야 해.\n","Simsimi > 회사 근처로 이사를 가보세요.\n","user > 우리집 강아지는 귀여워.\n","Simsimi > 아이스크림 먹어보세요.\n","user > 너무 바빠\n","Simsimi > 바빠도 힘내세요!\n","user > 빠\n","Simsimi > 잠시 쉬어가도 괜찮아요.\n","user > 팀 이름을 정해야 하는데 추천 좀 해줄래?\n","Simsimi > 저는 위로봇입니다.\n","user > 슬로건 만들어줘.\n","Simsimi > 제가 있잖아요.\n","user > 너는 누가 학습시켰니?\n","Simsimi > 다른 반 친구한테 부탁해보세요.\n","user > 이해를 잘 못하는구나.\n","Simsimi > 이해는 잘 안되나봐요.\n","user > 똑똑하네\n","Simsimi > 지금도 충분히 잘하고 있어요.\n","user > 네\n","Simsimi > 저도 궁금해요.\n","user > 너무 더워서 창문 열었어.\n","Simsimi > 창문 닫고 푹 쉬세요.\n","user > 이제 그만할게.\n","Simsimi > 시작이 반이에요.\n","user > 푹 쉬어.\n","Simsimi > 푹 쉬는 시간도 필요해요.\n","user > 이름이 뭐니?\n","Simsimi > 저는 위로봇입니다.\n","user > 잘자.\n","Simsimi > 잘자요.\n","user > 안녕.\n","Simsimi > 안녕.\n","user > 나는 안경을 쓰고있어.\n","Simsimi > 안경은 쓰고 다니세요.\n","user > 눈이 침침한데.\n","Simsimi > 눈을 깜빡거려보세요.\n","user > 허리도 아프고.\n","Simsimi > 스트레칭을 해보세요.\n","user > 무릎이 아파.\n","Simsimi > 무릎에 무리가 갈 거예요.\n","user > quit\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rIb9xyj3170U"},"execution_count":null,"outputs":[]}]}